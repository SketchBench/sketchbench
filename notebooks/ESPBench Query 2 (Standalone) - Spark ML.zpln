{
  "paragraphs": [
    {
      "title": "QuantileDiscretizer",
      "text": "%spark\n//All required imports to run this notebook\n\nimport org.apache.kafka.clients.consumer.ConsumerRecord\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport org.apache.spark.streaming.kafka010._\nimport org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent\nimport org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types.{StringType, StructField, StructType, IntegerType, DoubleType}\nimport org.apache.kafka.clients.consumer.ConsumerConfig\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport org.apache.spark.sql.SQLContext\nimport org.apache.spark.util.LongAccumulator\nimport org.apache.spark.streaming._\nimport org.apache.spark.ml.feature.QuantileDiscretizer\nimport scala.util.parsing.json.JSON\nimport java.util.{Calendar, Date}\nimport java.text.SimpleDateFormat\nimport sqlContext.implicits._\n",
      "user": "anonymous",
      "dateUpdated": "2021-08-02T06:06:24+0000",
      "progress": 0,
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "title": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 424,
              "optionOpen": false
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.kafka.clients.consumer.ConsumerRecord\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport org.apache.spark.streaming.kafka010._\nimport org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent\nimport org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types.{StringType, StructField, StructType, IntegerType, DoubleType}\nimport org.apache.kafka.clients.consumer.ConsumerConfig\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport org.apache.spark.sql.SQLContext\nimport org.apache.spark.util.LongAccumulator\nimport org.apache.spark.streaming._\nimport org.apache.spark.ml.feature.QuantileDiscretizer\nimport scala.util.pa...\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1627881342646_1382536249",
      "id": "paragraph_1626035545319_1260970793",
      "dateCreated": "2021-08-02T05:15:42+0000",
      "status": "READY",
      "focus": true,
      "$$hashKey": "object:2680"
    },
    {
      "text": "%spark\n\n// Variable initialization\n\nval ssc = new StreamingContext(sc, Seconds(300)) // 2min\nval sqlContext = new SQLContext(sc)\nval r = scala.util.Random\nval groupId = s\"stream-espbench-v${r.nextInt.toString}\"\nval batchesToRun = 3\nval topics = Array(\"SketchBench-1-1\")\nval dateFormat = new SimpleDateFormat(\"YYYY-MM-dd hh:mm:ss\")",
      "user": "anonymous",
      "dateUpdated": "2021-08-02T05:27:47+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[33mwarning: \u001b[0mthere was one deprecation warning (since 2.0.0); for details, enable `:setting -deprecation' or `:replay -deprecation'\n\u001b[1m\u001b[34mssc\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.streaming.StreamingContext\u001b[0m = org.apache.spark.streaming.StreamingContext@4d88328e\n\u001b[1m\u001b[34msqlContext\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.SQLContext\u001b[0m = org.apache.spark.sql.SQLContext@50c6fd9a\n\u001b[1m\u001b[34mr\u001b[0m: \u001b[1m\u001b[32mutil.Random.type\u001b[0m = scala.util.Random$@4dab1db7\n\u001b[1m\u001b[34mgroupId\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = stream-espbench-v-54685952\n\u001b[1m\u001b[34mbatchesToRun\u001b[0m: \u001b[1m\u001b[32mInt\u001b[0m = 3\n\u001b[1m\u001b[34mtopics\u001b[0m: \u001b[1m\u001b[32mArray[String]\u001b[0m = Array(SketchBench-1-1)\n\u001b[1m\u001b[34mdateFormat\u001b[0m: \u001b[1m\u001b[32mjava.text.SimpleDateFormat\u001b[0m = java.text.SimpleDateFormat@5963fda0\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1627881342646_1042317220",
      "id": "paragraph_1627112323857_186381451",
      "dateCreated": "2021-08-02T05:15:42+0000",
      "dateStarted": "2021-08-02T05:27:47+0000",
      "dateFinished": "2021-08-02T05:27:47+0000",
      "status": "FINISHED",
      "$$hashKey": "object:2681"
    },
    {
      "text": "%spark\n\n// Function for defining the batches to run the queries.\n\nobject FinishedBatchesCounter {\n  @volatile private var instance: LongAccumulator = null\n\n  def getInstance(sc: SparkContext): LongAccumulator = {\n    if (instance == null) {\n      synchronized {\n        if (instance == null) {\n      \tinstance = sc.longAccumulator(\"FinishedBatchesCounter\")\n        }\n      }\n    }\n    instance\n  }\n}\n",
      "user": "anonymous",
      "dateUpdated": "2021-08-02T05:27:50+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "defined object FinishedBatchesCounter\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1627881342646_922008961",
      "id": "paragraph_1627112367281_1356959987",
      "dateCreated": "2021-08-02T05:15:42+0000",
      "dateStarted": "2021-08-02T05:27:50+0000",
      "dateFinished": "2021-08-02T05:27:50+0000",
      "status": "FINISHED",
      "$$hashKey": "object:2682"
    },
    {
      "text": "%spark\n\n// Kafka Connection details     \nval kafkaParams = Map[String, Object](\n  \"bootstrap.servers\" -> \"sketchbench-kafka:9092\",\n  \"key.deserializer\" -> classOf[StringDeserializer],\n  \"value.deserializer\" -> classOf[StringDeserializer],\n  \"auto.offset.reset\" -> \"latest\",\n  \"group.id\" -> groupId,\n  \"enable.auto.commit\" -> (true: java.lang.Boolean)\n)\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-08-02T05:27:52+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mkafkaParams\u001b[0m: \u001b[1m\u001b[32mscala.collection.immutable.Map[String,Object]\u001b[0m = Map(key.deserializer -> class org.apache.kafka.common.serialization.StringDeserializer, auto.offset.reset -> latest, group.id -> stream-espbench-v-54685952, bootstrap.servers -> sketchbench-kafka:9092, enable.auto.commit -> true, value.deserializer -> class org.apache.kafka.common.serialization.StringDeserializer)\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1627881342646_1009014212",
      "id": "paragraph_1627112430259_454609685",
      "dateCreated": "2021-08-02T05:15:42+0000",
      "dateStarted": "2021-08-02T05:27:52+0000",
      "dateFinished": "2021-08-02T05:27:52+0000",
      "status": "FINISHED",
      "$$hashKey": "object:2683"
    },
    {
      "text": "%spark\n\n// Connect to Kafka and establish streaming for windows.\nval stream = KafkaUtils.createDirectStream[String, String](\n  ssc,\n  PreferConsistent,\n  Subscribe[String, String](topics, kafkaParams)\n)\n\n",
      "user": "anonymous",
      "dateUpdated": "2021-08-02T05:27:56+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mstream\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.streaming.dstream.InputDStream[org.apache.kafka.clients.consumer.ConsumerRecord[String,String]]\u001b[0m = org.apache.spark.streaming.kafka010.DirectKafkaInputDStream@773532a4\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1627881342646_1531493674",
      "id": "paragraph_1627112465726_2071867502",
      "dateCreated": "2021-08-02T05:15:42+0000",
      "dateStarted": "2021-08-02T05:27:56+0000",
      "dateFinished": "2021-08-02T05:27:56+0000",
      "status": "FINISHED",
      "$$hashKey": "object:2684"
    },
    {
      "text": "%spark\n// Process the messages from the stream and calculate Min, Max, Avg and Count of messages in each batch\nval messages = stream\n    .map(record => record.value)\n    .flatMap(record => {\n         JSON.parseFull(record).map(rawMap =>{\n            val map = rawMap.asInstanceOf[Map[String,String]]\n            map\n         } )\n    })\n\nval start = Calendar.getInstance().getTime()\nprintln(s\"--- Start Time - UTC: \"+dateFormat.format(start))\n// val windowStream = messages.window(Seconds(300), Seconds(300)) // 5min\n\nmessages.foreachRDD { rdd =>\n  val finishedBatchesCounter = FinishedBatchesCounter.getInstance(sc)\n  println(s\">>> Batch ${finishedBatchesCounter.count + 1} ---\")\n  val newRDD = rdd.map(p => Row(p.get(\"mf01\").get))\n  val columns = Seq(\"mf01\")\n  val schema = StructType(columns.map(fieldName => StructField(fieldName, DoubleType, nullable = true)))\n  val rddDF = spark.createDataFrame(newRDD,schema)\n  val discretizer = new QuantileDiscretizer()\n      .setInputCol(\"mf01\")\n      .setOutputCol(\"result\")\n      .setNumBuckets(11)\n  \n  val result = discretizer.fit(rddDF).transform(rddDF)\n  result.groupBy(\"result\").agg(min(\"mf01\"),max(\"mf01\"),avg(\"mf01\"),count(\"mf01\")).orderBy(\"result\").show(false)\n\n//   println(s\"--- Processing Time in Millis - \"+diff)\n//   println(\"--- Processed messages in this batch: \" + rdd.count()) \n    \n  if (finishedBatchesCounter.count >= batchesToRun - 1) {\n    val end = Calendar.getInstance().getTime()\n    println(s\"--- End Time - UTC: \"+dateFormat.format(end))\n    ssc.stop(false)\n  } else {\n    finishedBatchesCounter.add(1)\n  }\n}\n\nssc.start()  \nssc.awaitTermination()",
      "user": "anonymous",
      "dateUpdated": "2021-08-02T05:28:11+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[33mwarning: \u001b[0mthere was one deprecation warning (since 1.0.6); for details, enable `:setting -deprecation' or `:replay -deprecation'\n--- Start Time - UTC: 2021-08-02 05:28:11\n>>> Batch 1 ---\n+------+---------+---------+------------------+-----------+\n|result|min(mf01)|max(mf01)|avg(mf01)         |count(mf01)|\n+------+---------+---------+------------------+-----------+\n|0.0   |12320.0  |12637.0  |12564.752199759158|156949     |\n|1.0   |12638.0  |12691.0  |12668.676191524064|154508     |\n|2.0   |12692.0  |12757.0  |12714.7674005002  |161935     |\n|3.0   |12758.0  |14030.0  |13797.107764235061|158921     |\n|4.0   |14031.0  |14522.0  |14269.646741715555|157675     |\n|5.0   |14524.0  |14696.0  |14629.492313994895|158665     |\n|6.0   |14697.0  |14778.0  |14738.688192941385|158473     |\n|7.0   |14779.0  |14855.0  |14816.546511479184|156370     |\n|8.0   |14856.0  |14956.0  |14902.778628042148|160865     |\n|9.0   |14957.0  |15119.0  |15029.780501612462|157213     |\n|10.0  |15120.0  |20797.0  |15551.872861113387|158669     |\n+------+---------+---------+------------------+-----------+\n\n>>> Batch 2 ---\n+------+---------+---------+------------------+-----------+\n|result|min(mf01)|max(mf01)|avg(mf01)         |count(mf01)|\n+------+---------+---------+------------------+-----------+\n|0.0   |12260.0  |12575.0  |12528.049205170108|437515     |\n|1.0   |12576.0  |12620.0  |12598.8153988393  |429396     |\n|2.0   |12621.0  |12671.0  |12643.20432433662 |439605     |\n|3.0   |12672.0  |14007.0  |13127.74087587064 |436891     |\n|4.0   |14008.0  |14529.0  |14222.918876151307|436678     |\n|5.0   |14531.0  |14780.0  |14693.893629804936|436062     |\n|6.0   |14781.0  |14870.0  |14828.630393773437|437866     |\n|7.0   |14871.0  |14948.0  |14909.507768868078|432238     |\n|8.0   |14949.0  |15046.0  |14994.525372890694|441081     |\n|9.0   |15047.0  |15203.0  |15118.278763548775|435925     |\n|10.0  |15204.0  |24313.0  |15629.122492157627|436730     |\n+------+---------+---------+------------------+-----------+\n\n>>> Batch 3 ---\n+------+---------+---------+------------------+-----------+\n|result|min(mf01)|max(mf01)|avg(mf01)         |count(mf01)|\n+------+---------+---------+------------------+-----------+\n|0.0   |12345.0  |13968.0  |12996.230490172818|434153     |\n|1.0   |13969.0  |14336.0  |14142.13822184952 |438838     |\n|2.0   |14338.0  |14695.0  |14535.481936537704|434053     |\n|3.0   |14696.0  |14831.0  |14773.923064041037|435908     |\n|4.0   |14832.0  |14901.0  |14868.28606646085 |438905     |\n|5.0   |14903.0  |14961.0  |14932.53298115102 |438220     |\n|6.0   |14963.0  |15022.0  |14992.321549767297|437898     |\n|7.0   |15023.0  |15092.0  |15055.538700780198|431813     |\n|8.0   |15093.0  |15186.0  |15136.648228925551|433748     |\n|9.0   |15187.0  |15352.0  |15258.527299180467|439885     |\n|10.0  |15353.0  |20989.0  |15855.026500593229|436594     |\n+------+---------+---------+------------------+-----------+\n\n--- End Time - UTC: 2021-08-02 06:01:29\n\u001b[1m\u001b[34mmessages\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.streaming.dstream.DStream[scala.collection.immutable.Map[String,String]]\u001b[0m = org.apache.spark.streaming.dstream.FlatMappedDStream@600e8cac\n\u001b[1m\u001b[34mstart\u001b[0m: \u001b[1m\u001b[32mjava.util.Date\u001b[0m = Mon Aug 02 05:28:11 GMT 2021\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1627881342646_558649535",
      "id": "paragraph_1627112487810_608870197",
      "dateCreated": "2021-08-02T05:15:42+0000",
      "dateStarted": "2021-08-02T05:28:11+0000",
      "dateFinished": "2021-08-02T06:01:31+0000",
      "status": "ABORT",
      "$$hashKey": "object:2685"
    }
  ],
  "name": "ESPBench Query 2 (Standalone) - Spark ML",
  "id": "2GE3G86JC",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/ESPBench Query 2 (Standalone) - Spark ML"
}