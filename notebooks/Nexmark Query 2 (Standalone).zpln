{
  "paragraphs": [
    {
      "text": "%md\n## Query: Top 10 Auctions by bid count\n\n**CQL:**\n\n```\nSELECT TOP(10, auction_id)\nFROM STREAM(300000, TIME);\n```\nOR\n\n\n```\nSELECT auction_id, COUNT(*) as total_bids\nFROM STREAM(300000, TIME) \nGROUP BY 1 \nORDER BY 2 DESC \nLIMIT 10;\n```",
      "user": "anonymous",
      "dateUpdated": "2021-07-31T05:38:59+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 321.188,
              "optionOpen": false
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Query: Top 10 Auctions by bid count</h2>\n<p><strong>CQL:</strong></p>\n<pre><code>SELECT TOP(10, auction_id)\nFROM STREAM(300000, TIME);\n</code></pre>\n<p>OR</p>\n<pre><code>SELECT auction_id, COUNT(*) as total_bids\nFROM STREAM(300000, TIME) \nGROUP BY 1 \nORDER BY 2 DESC \nLIMIT 10;\n</code></pre>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1627705095019_1312488377",
      "id": "paragraph_1627432435328_550499922",
      "dateCreated": "2021-07-31T04:18:15+0000",
      "dateStarted": "2021-07-31T05:38:59+0000",
      "dateFinished": "2021-07-31T05:39:01+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:283"
    },
    {
      "title": " Top 10 Auctions by bid count",
      "text": "%spark\nimport org.apache.kafka.clients.consumer.ConsumerRecord\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport org.apache.spark.streaming.kafka010._\nimport org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent\nimport org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe\nimport org.apache.spark.SparkContext\n\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types.{StringType, StructField, StructType, DoubleType}\n\nimport org.apache.kafka.clients.consumer.ConsumerConfig\nimport org.apache.kafka.common.serialization.StringDeserializer\n\nimport org.apache.spark.sql.SQLContext\n\nimport org.apache.spark.util.LongAccumulator\nimport org.apache.spark.streaming._\n\nimport org.apache.spark.ml.feature.QuantileDiscretizer\n\nimport scala.util.parsing.json.JSON\nimport java.util.{Calendar, Date}\nimport java.text.SimpleDateFormat\n\n\nval r = scala.util.Random\nval groupId = s\"stream-nexmark-v${r.nextInt.toString}\"\n \n\nval runDurtion = 300000\nval windowDuration = 120\nval checkpointDuration = 120\nval microbatchDuration = 2\nval topic = s\"NEXMarkTest1\"\nval kafkaEndpoint = s\"kafka:9092\"\nval checkpointLocation = s\"hdfs://namenode:9000/tmp/checkpoint/\"+groupId\n\nval ssc = new StreamingContext(sc, Seconds(microbatchDuration))\n\nval sqlContext = new SQLContext(sc)\nimport sqlContext.implicits._\n\nval kafkaParams = Map[String, Object](\n  \"bootstrap.servers\" -> kafkaEndpoint,\n  \"key.deserializer\" -> classOf[StringDeserializer],\n  \"value.deserializer\" -> classOf[StringDeserializer],\n  \"group.id\" -> groupId,\n  \"auto.offset.reset\" -> \"latest\",\n  \"enable.auto.commit\" -> (false: java.lang.Boolean)\n)\n\nval topics = Array(topic)\nval stream = KafkaUtils.createDirectStream[String, String](\n  ssc,\n  PreferConsistent,\n  Subscribe[String, String](topics, kafkaParams)\n)\n\nssc.checkpoint(\"hdfs://namenode:9000/tmp/checkpoint-test/\") \n\n\nval messages = stream\n    .map(record => record.value)\n    .flatMap(record => {\n         JSON.parseFull(record).map(rawMap =>{\n            val map = rawMap.asInstanceOf[Map[String,Map[String,Double]]]\n            val inMap = map.get(\"event\")\n            val dt = new Date(inMap.get(\"time\").toLong)\n            (inMap.get(\"auction_id\").toInt, inMap.get(\"bid\").toInt)\n         } )\n    })\n\nmessages.checkpoint(Seconds(checkpointDuration))\n\ndef updateStateFunc(bids: Seq[(Int)], runningstate: Option[(Long)]):  Option[(Long)] = {\n\n    val previousState = runningstate.getOrElse(0l)\n    var newState = previousState\n    if(!bids.isEmpty) {\n\n        val count = previousState\n        \n        val currCount = bids.length\n        \n        val newCount = count + currCount\n        newState = (newCount)\n    }\n        \n    Some(newState)\n}\n\nval result = messages.updateStateByKey(updateStateFunc _)\n\nval windowedResult = result.window(Seconds(windowDuration),Seconds(windowDuration))\n\nval n = 100\nval topN = windowedResult.reduceByKey(_ + _).transform(rdd =>{\n   val list = rdd.sortBy(_._2,false).take(n)\n   rdd.filter(list.contains)\n})\ntopN.print\n\n\nssc.start()  \nssc.awaitTerminationOrTimeout(runDurtion)\nssc.stop()",
      "user": "anonymous",
      "dateUpdated": "2021-07-31T06:14:58+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[33mwarning: \u001b[0mthere was one deprecation warning (since 1.0.6)\n\u001b[33mwarning: \u001b[0mthere was one deprecation warning (since 2.0.0)\n\u001b[33mwarning: \u001b[0mthere were two deprecation warnings in total; for details, enable `:setting -deprecation' or `:replay -deprecation'\n-------------------------------------------\nTime: 1627712240000 ms\n-------------------------------------------\n(20546,300)\n(11552,240)\n(20956,300)\n(17930,240)\n(12398,300)\n(21240,240)\n(17384,240)\n(17770,240)\n(16994,300)\n(17670,240)\n...\n\n-------------------------------------------\nTime: 1627712360000 ms\n-------------------------------------------\n(10984,360)\n(19226,420)\n(14326,360)\n(12398,360)\n(21240,420)\n(17770,360)\n(16994,360)\n(17670,360)\n(20272,360)\n(20204,420)\n...\n\nimport org.apache.kafka.clients.consumer.ConsumerRecord\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport org.apache.spark.streaming.kafka010._\nimport org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent\nimport org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.types.{StringType, StructField, StructType, DoubleType}\nimport org.apache.kafka.clients.consumer.ConsumerConfig\nimport org.apache.kafka.common.serialization.StringDeserializer\nimport org.apache.spark.sql.SQLContext\nimport org.apache.spark.util.LongAccumulator\nimport org.apache.spark.streaming._\nimport org.apache.spark.ml.feature.QuantileDiscretizer\nimport scala.util.parsing.json.JS...\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1627705095022_694182641",
      "id": "paragraph_1627434483639_1937179438",
      "dateCreated": "2021-07-31T04:18:15+0000",
      "dateStarted": "2021-07-31T06:14:58+0000",
      "dateFinished": "2021-07-31T06:20:23+0000",
      "status": "FINISHED",
      "$$hashKey": "object:284"
    },
    {
      "text": "%spark\n",
      "user": "anonymous",
      "dateUpdated": "2021-07-31T04:18:15+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1627705095023_709319282",
      "id": "paragraph_1627436681375_367010683",
      "dateCreated": "2021-07-31T04:18:15+0000",
      "status": "READY",
      "$$hashKey": "object:285"
    }
  ],
  "name": "Nexmark Query 2 (Standalone)",
  "id": "2GD7YC4TY",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/Nexmark Query 2 (Standalone)"
}