### Benchmark Control Plane ###

dataIngestion:
  espbench:
    enabled: true
    nodeSelector:
      sketchbench/pool: data-ingestion
    # 125000 ns interval = 8,000 msg /sec
    # 1000000 ns interval = 1,000 msg /sec
    sendingInterval: 125000
    sendingIntervalTimeUnit: NANOSECONDS
    duration: 1
    durationTimeUnit: HOURS
    replicaCount: 3
    resources:
      requests:
        memory: "12Gi"
        cpu: "3"
      limits:
        memory: "12Gi"

spark: # System Under Test (isolated Spark cluster)
  enabled: true
  image:
    repository: sketchbench/bullet-spark-3.0
    tag: "1.0.4"
    pullPolicy: IfNotPresent
  worker:
    replicaCount: 3
    coreLimit: 6
    nodeSelector:
      sketchbench/pool: system-under-test
    resources:
      requests:
        memory: "27Gi"
        cpu: "7"
      limits:
        memory: "27Gi"
  master:
    nodeSelector:
      sketchbench/pool: system-under-test
    resources:
      requests:
        memory: "27Gi"
        cpu: "7"
      limits:
        memory: "27Gi"
  podAntiAffinitypreset: hard
  metrics:
    enabled: true
    podMonitor:
      enabled: true
      interval: 5s

hdfs:
  enabled: true
  namenode:
    nodeSelector:
      sketchbench/pool: data-plane
  datanode:
    nodeSelector:
      sketchbench/pool: data-plane
  shell:
    nodeSelector:
      sketchbench/pool: data-plane

zeppelin:
  enabled: true
  resources:
    requests:
      memory: "27Gi"
      cpu: "7"
    limits:
      memory: "27Gi"
  nodeSelector:
    sketchbench/pool: system-under-test
  runMode: local
  interpreters:
    - file
    - spark
    - md
    - python
    - sh
  metrics:
    enabled: true
    podMonitor:
      enabled: true
      interval: 5s
  sparkInterpreter:
    spark:
      master: "spark://sketchbench-espbench-spark-master-svc:7077"
      submit:
        deployMode: "client"
      app:
        name: BulletSparkStreamingJob
      jar:
        packages: org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.2,org.apache.spark:spark-streaming-kafka-0-10-assembly_2.12:3.0.2
      cores:
        max: 18
      driver:
        cores: 3
        memory: 13g
      executor:
        cores: 3
        memory: 13g
# driver
# - --conf
# - spark.streaming.backpressure.enabled=true
# - --conf
# - spark.dynamicAllocation.enabled=false
# - --conf
# - spark.driver.extraJavaOptions="-XX:+UseG1GC"
# - --conf
# - spark.executor.extraJavaOptions="-XX:+UseG1GC"

### Data Ingestion (isolated Kafka cluster) ###

kafka:
  nodeSelector:
    sketchbench/pool: data-ingestion
  podAntiAffinitypreset: hard
  logRetentionHours: 6
  numPartitions: 5
  deleteTopicEnable: true
  resources:
    requests:
      memory: "12Gi"
      cpu: "3"
    limits:
      memory: "12Gi"
  persistence:
    size: 32Gi
  logPersistence:
    size: 32Gi
  metrics:
    kafka:
      enabled: true
      nodeSelector:
        sketchbench/pool: observability
    jmx:
      enabled: true
    serviceMonitor:
      enabled: true
  zookeeper:
    nodeSelector:
      sketchbench/pool: data-plane
    metrics:
      enabled: true
      serviceMonitor:
        enabled: true

### Benchmark Observability Stack ###

kafdrop:
  enabled: true
  deployment:
    nodeSelector:
      sketchbench/pool: observability

tobs:
  enabled: true
  kube-prometheus-stack:
    alertmanager:
      enabled: false # not needed
    grafana:
      nodeSelector:
        sketchbench/pool: observability
    kube-state-metrics:
      nodeSelector:
        sketchbench/pool: observability
    prometheus:
      prometheusSpec:
        scrapeInterval: 5s
        scrapeTimeout: 5s
        nodeSelector:
          sketchbench/pool: observability
        podMonitorSelectorNilUsesHelmValues: false
        serviceMonitorSelectorNilUsesHelmValues: false
    prometheusOperator:
      nodeSelector:
        sketchbench/pool: observability
  promscale:
    maintenance:
      nodeSelector:
        sketchbench/pool: observability
    nodeSelector:
      sketchbench/pool: observability
  timescaledb-single:
    nodeSelector:
      sketchbench/pool: observability
