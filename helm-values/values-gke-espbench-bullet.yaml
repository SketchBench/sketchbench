### Configurable SketchBench Data Generation (ESPBench) ###
dataIngestion:
  espbench:
    enabled: true
    nodeSelector:
      sketchbench/pool: data-generation
    # 125000 ns interval = 8,000 msg /sec
    # 1000000 ns interval = 1,000 msg /sec
    sendingInterval: 125000
    sendingIntervalTimeUnit: NANOSECONDS
    duration: 1
    durationTimeUnit: HOURS
    replicaCount: 1
    resources:
      requests:
        memory: "12Gi"
        cpu: "3"
      limits:
        memory: "12Gi"

### Bullet Stack ###
bullet:
  enabled: true
  spark:
    enabled: false
  hdfs:
    enabled: false
  pubsub:
    nodeSelector:
      sketchbench/pool: control-plane
    persistence:
      size: 50Gi
    metrics:
      kafka:
        enabled: true
        nodeSelector:
          sketchbench/pool: observability
      jmx:
        enabled: true
      serviceMonitor:
        enabled: true
        interval: 10s
    zookeeper:
      nodeSelector:
        sketchbench/pool: data-plane
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true
          interval: 10s
  pubsubMonit:
    deployment:
      nodeSelector:
        sketchbench/pool: observability
  ui:
    nodeSelector:
      sketchbench/pool: control-plane
  webservice:
    nodeSelector:
      sketchbench/pool: control-plane
  sparkBackend:
    nodeSelector:
      sketchbench/pool: system-under-test
    resources:
      requests:
        memory: "27Gi"
        cpu: "7"
      limits:
        memory: "27Gi"
    image:
      repository: sketchbench/bullet-spark-3.0
    hdfsUser: hadoop
    hdfs:
      ports:
        clientRpc: 8020
    cluster:
      clusterPort: 7077
    metrics:
      enabled: true
      podMonitor:
        enabled: true
      graphiteExporter:
        enabled: true
        host: graphite-exporter
        port: 9109
        periodSeconds: 10
    driver:
      confs:
        - --conf
        - spark.cores.max=36
        - --conf
        - spark.executor.cores=6
        - --conf
        - spark.executor.memory=26G
        - --conf
        - spark.streaming.backpressure.enabled=true
        - --conf
        - spark.dynamicAllocation.enabled=false
        - --conf
        - spark.driver.extraJavaOptions="-XX:+UseG1GC"
        - --conf
        - spark.executor.extraJavaOptions="-XX:+UseG1GC"
    config:
      bullet:
        spark:
          app:
            name: SketchBench
          batch:
            duration:
              ms: 2000
          data:
            producer:
              parallelism: 5
          filter:
            partition:
              parallel:
                mode:
                  enabled: true
                  parallelism: 5
          query:
            union:
              checkpoint:
                duration:
                  multiplier: 20
          join:
            checkpoint:
              duration:
                multiplier: 20
          metrics:
            enabled: false
          dsl:
            data:
              producer:
                enable: true
            deserializer:
              enable: false
        dsl:
          connector:
            class:
              name: com.yahoo.bullet.dsl.connector.KafkaConnector
            kafka:
              topics:
                - SketchBench-1-1
              bootstrap:
                servers:
                  - kafka:9092
              start:
                at:
                  end:
                    enable: true
          converter:
            class:
              name: com.yahoo.bullet.dsl.converter.JSONBulletRecordConverter
            schema:
              type:
                check:
                  enable: false
          deserializer:
            class:
              name: com.yahoo.bullet.dsl.deserializer.IdentityDeserializer
    dsl:
      schema: |
        {
          "fields": [
            {
              "name": "messageID",
              "type": "INTEGER"
            },
            {
              "name": "ts",
              "type": "STRING"
            },
            {
              "name": "index",
              "type": "LONG"
            },
            {
              "name": "mf01",
              "type": "INTEGER"
            },
            {
              "name": "mf02",
              "type": "INTEGER"
            },
            {
              "name": "mf03",
              "type": "INTEGER"
            },
            {
              "name": "pc13",
              "type": "INTEGER"
            },
            {
              "name": "pc14",
              "type": "INTEGER"
            },
            {
              "name": "pc15",
              "type": "INTEGER"
            },
            {
              "name": "pc25",
              "type": "INTEGER"
            },
            {
              "name": "pc26",
              "type": "INTEGER"
            },
            {
              "name": "pc27",
              "type": "INTEGER"
            },
            {
              "name": "res",
              "type": "INTEGER"
            }
          ]
        }


### Apache Zeppelin for benchmark notebooks ###
zeppelin:
  enabled: true
  nodeSelector:
    sketchbench/pool: control-plane
  runMode: local
  interpreters:
    - file
    - md
    - python
    - sh
  metrics:
    enabled: true
    podMonitor:
      enabled: true

### System Under Test (isolated Apache Spark cluster) ###
spark:
  enabled: true
  image:
    repository: sketchbench/bullet-spark-3.0
    tag: "1.0.4"
    pullPolicy: IfNotPresent
  worker:
    replicaCount: 6
    coreLimit: 6
    nodeSelector:
      sketchbench/pool: system-under-test
    resources:
      requests:
        memory: "27Gi"
        cpu: "7"
      limits:
        memory: "27Gi"
  master:
    nodeSelector:
      sketchbench/pool: system-under-test
    resources:
      requests:
        memory: "27Gi"
        cpu: "7"
      limits:
        memory: "27Gi"
  podAntiAffinitypreset: hard
  metrics:
    enabled: true
    podMonitor:
      enabled: true
      interval: 10s

### HDFS for checkpointing ###
hdfs:
  enabled: true
  namenode:
    nodeSelector:
      sketchbench/pool: data-plane
  datanode:
    nodeSelector:
      sketchbench/pool: data-plane
  shell:
    nodeSelector:
      sketchbench/pool: data-plane

### Data Ingestion (isolated Apache Kafka cluster) ###
kafka:
  nodeSelector:
    sketchbench/pool: data-ingestion
  podAntiAffinitypreset: hard
  logRetentionHours: 12
  numPartitions: 5
  deleteTopicEnable: true
  resources:
    requests:
      memory: "12Gi"
      cpu: "3"
    limits:
      memory: "12Gi"
  persistence:
    size: 100Gi
  metrics:
    kafka:
      enabled: true
      nodeSelector:
        sketchbench/pool: observability
    jmx:
      enabled: true
    serviceMonitor:
      enabled: true
      interval: 10s
  zookeeper:
    nodeSelector:
      sketchbench/pool: data-plane
    metrics:
      enabled: true
      serviceMonitor:
        enabled: true
        interval: 10s

### Benchmark Observability Stack ###
kafdrop:
  enabled: true
  deployment:
    nodeSelector:
      sketchbench/pool: observability
tobs:
  enabled: true
  kube-prometheus-stack:
    alertmanager:
      enabled: false # not needed
    grafana:
      sidecar:
        datasources:
          defaultDatasourceScrapeInterval: 10s
      nodeSelector:
        sketchbench/pool: observability
    kube-state-metrics:
      nodeSelector:
        sketchbench/pool: observability
    kubeStateMetrics:
      serviceMonitor:
        interval: 10s
    nodeExporter:
      serviceMonitor:
        interval: 10s
    prometheus:
      prometheusSpec:
        scrapeInterval: 10s
        scrapeTimeout: 10s
        evaluationInterval: 10s
        nodeSelector:
          sketchbench/pool: observability
        podMonitorSelectorNilUsesHelmValues: false
        serviceMonitorSelectorNilUsesHelmValues: false
        storageSpec:
          volumeClaimTemplate:
            spec:
              resources:
                requests:
                  storage: 50Gi
    prometheusOperator:
      nodeSelector:
        sketchbench/pool: observability
  promscale:
    maintenance:
      nodeSelector:
        sketchbench/pool: observability
    nodeSelector:
      sketchbench/pool: observability
  timescaledb-single:
    nodeSelector:
      sketchbench/pool: observability
    persistentVolumes:
      data:
        size: 50Gi
      wal:
        size: 50Gi
graphite-exporter:
  enabled: true
  nodeSelector:
    sketchbench/pool: observability
  podMonitor:
    enabled: true
    interval: 10s
