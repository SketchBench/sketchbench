### Benchmark Control Plane ###

dataIngestion:
  espbench:
    enabled: true
    nodeSelector:
      sketchbench/pool: benchmark-control-plane
    # 10000 ns interval = 100,000 msg/sec
    # 1000000 ns interval = 1,000 msg /sec
    sendingInterval: 1000000
    sendingIntervalTimeUnit: NANOSECONDS
    duration: 1
    durationTimeUnit: HOURS

bullet:
  enabled: true
  spark:
    # Use SketchBench-managed Spark instance in separate node pool
    enabled: false
  hdfs:
    namenode:
      nodeSelector:
        sketchbench/pool: data-plane
    datanode:
      nodeSelector:
        sketchbench/pool: data-plane
    shell:
      nodeSelector:
        sketchbench/pool: data-plane
  pubsub:
    nodeSelector:
      sketchbench/pool: benchmark-control-plane
    metrics:
      kafka:
        enabled: true
        nodeSelector:
          sketchbench/pool: observability
      jmx:
        enabled: true
      serviceMonitor:
        enabled: true
    zookeeper:
      nodeSelector:
        sketchbench/pool: data-plane
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true
  pubsubMonit:
    nodeSelector:
      sketchbench/pool: observability
  ui:
    nodeSelector:
      sketchbench/pool: benchmark-control-plane
  webservice:
    nodeSelector:
      sketchbench/pool: benchmark-control-plane
  sparkBackend:
    executorCores: 3
    executorMemory: 9G
    nodeSelector:
      sketchbench/pool: system-under-test
    image:
      repository: sketchbench/bullet-spark-3.0
    hdfsUser: hadoop
    hdfs:
      port: 8020
    config:
      bullet:
        spark:
          dsl:
            data:
              producer:
                enable: true
            deserializer:
              enable: false
        dsl:
          connector:
            class:
              name: com.yahoo.bullet.dsl.connector.KafkaConnector
            kafka:
              topics:
                - SketchBench-1-1
              bootstrap:
                servers:
                  - kafka:9092
          converter:
            class:
              name: com.yahoo.bullet.dsl.converter.JSONBulletRecordConverter
            schema:
              type:
                check:
                  enable: false
          deserializer:
            class:
              name: com.yahoo.bullet.dsl.deserializer.IdentityDeserializer
    dsl:
      schema: |
        {
          "fields": [
            {
              "name": "messageID",
              "type": "INTEGER"
            },
            {
              "name": "ts",
              "type": "STRING"
            },
            {
              "name": "index",
              "type": "LONG"
            },
            {
              "name": "mf01",
              "type": "INTEGER"
            },
            {
              "name": "mf02",
              "type": "INTEGER"
            },
            {
              "name": "mf03",
              "type": "INTEGER"
            },
            {
              "name": "pc13",
              "type": "INTEGER"
            },
            {
              "name": "pc14",
              "type": "INTEGER"
            },
            {
              "name": "pc15",
              "type": "INTEGER"
            },
            {
              "name": "pc25",
              "type": "INTEGER"
            },
            {
              "name": "pc26",
              "type": "INTEGER"
            },
            {
              "name": "pc27",
              "type": "INTEGER"
            },
            {
              "name": "res",
              "type": "INTEGER"
            }
          ]
        }

zeppelin:
  enabled: true
  deployment:
    nodeSelector:
      sketchbench/pool: benchmark-control-plane
  runMode: local
  interpreters:
    - file
    - spark
    - md
    - python
  sparkInterpreter:
    spark:
      master: "spark://my-sketchbench-spark-master-svc:7077"
      submit:
        deployMode: "client"
      app:
        name: "zeppelin"
      jar:
        packages: org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.2,org.apache.spark:spark-streaming-kafka-0-10-assembly_2.12:3.0.2
### Benchmark Observability Stack ###

tobs:
  enabled: true
  kube-prometheus-stack:
    alertmanager:
      alertmanagerSpec:
        nodeSelector:
          sketchbench/pool: observability
    grafana:
      nodeSelector:
        sketchbench/pool: observability
    kube-state-metrics:
      nodeSelector:
        sketchbench/pool: observability
    prometheus:
      prometheusSpec:
        nodeSelector:
          sketchbench/pool: observability
    prometheusOperator:
      admissionWebhooks:
        patch:
          nodeSelector:
            sketchbench/pool: observability
      nodeSelector:
        sketchbench/pool: observability
  promscale:
    maintenance:
      nodeSelector:
        sketchbench/pool: observability
    nodeSelector:
      sketchbench/pool: observability
  timescaledb-single:
    nodeSelector:
      sketchbench/pool: observability

kafdrop:
  enabled: true
  deployment:
    nodeSelector:
      sketchbench/pool: observability

### Data Ingestion (isolated Kafka cluster) ###

kafka:
  nodeSelector:
    sketchbench/pool: data-ingestion
  podAntiAffinitypreset: hard
  logRetentionHours: 6
  metrics:
    kafka:
      enabled: true
      nodeSelector:
        sketchbench/pool: observability
    jmx:
      enabled: true
    serviceMonitor:
      enabled: true
  zookeeper:
    nodeSelector:
      sketchbench/pool: data-ingestion
    metrics:
      enabled: true
      serviceMonitor:
        enabled: true

### System Under Test (isolated Spark cluster) ###

spark:
  enabled: true
  image:
    repository: sketchbench/bullet-spark-3.0
    tag: "1.0.4"
    pullPolicy: IfNotPresent
  worker:
    replicaCount: 4
    coreLimit: 3
    nodeSelector:
      sketchbench/pool: system-under-test
    resources:
      requests:
        memory: "10Gi"
        cpu: "3.25"
      limits:
        memory: "10Gi"
        cpu: "3.25"
  master:
    nodeSelector:
      sketchbench/pool: system-under-test
    resources:
      requests:
        memory: "10Gi"
        cpu: "3.5"
      limits:
        memory: "10Gi"
        cpu: "3.5"
  podAntiAffinitypreset: hard
  metrics:
    enabled: true
    podMonitor:
      enabled: true
