### Benchmark Control Plane ###

dataIngestion:
  espbench:
    enabled: true
    # 125000 ns interval = 8,000 msg /sec
    # 1000000 ns interval = 1,000 msg /sec
    sendingInterval: 1000000
    sendingIntervalTimeUnit: NANOSECONDS
    duration: 1
    durationTimeUnit: HOURS

bullet:
  enabled: true
  spark: # System Under Test (isolated Spark cluster)
    enabled: true
    image:
      repository: sketchbench/bullet-spark-3.0
      tag: "1.0.4"
      pullPolicy: IfNotPresent
    worker:
      replicaCount: 2
      coreLimit: 2
      resources:
        requests:
          memory: "5Gi"
          cpu: "2.25"
        limits:
          memory: "5Gi"
          cpu: "2.25"
    master:
      resources:
        requests:
          memory: "5Gi"
          cpu: "2.25"
        limits:
          memory: "5Gi"
          cpu: "2.25"
    podAntiAffinitypreset: hard
    metrics:
      enabled: true
      podMonitor:
        enabled: true
  pubsub:
    metrics:
      kafka:
        enabled: true
      jmx:
        enabled: true
      serviceMonitor:
        enabled: true
    zookeeper:
      metrics:
        enabled: true
        serviceMonitor:
          enabled: true
  sparkBackend:
    executorCores: 2
    executorMemory: 4G
    resources:
      requests:
        memory: "5Gi"
        cpu: "2.25"
      limits:
        memory: "5Gi"
        cpu: "2.25"
    image:
      repository: sketchbench/bullet-spark-3.0
    hdfsUser: hadoop
    hdfs:
      port: 8020
    metrics:
      enabled: true
      podMonitor:
        enabled: true
    config:
      bullet:
        spark:
          data:
            producer:
              parallelism: 2
          # filter:
          #   partition:
          #     parallel:
          #       mode:
          #         enabled: true
          #         parallelism: 3
          metrics:
            enabled: true
          dsl:
            data:
              producer:
                enable: true
            deserializer:
              enable: false
        dsl:
          connector:
            class:
              name: com.yahoo.bullet.dsl.connector.KafkaConnector
            kafka:
              topics:
                - SketchBench-1-1
              bootstrap:
                servers:
                  - kafka:9092
              start:
                at:
                  end:
                    enable: true
          converter:
            class:
              name: com.yahoo.bullet.dsl.converter.JSONBulletRecordConverter
            schema:
              type:
                check:
                  enable: false
          deserializer:
            class:
              name: com.yahoo.bullet.dsl.deserializer.IdentityDeserializer
    dsl:
      schema: |
        {
          "fields": [
            {
              "name": "messageID",
              "type": "INTEGER"
            },
            {
              "name": "ts",
              "type": "STRING"
            },
            {
              "name": "index",
              "type": "LONG"
            },
            {
              "name": "mf01",
              "type": "INTEGER"
            },
            {
              "name": "mf02",
              "type": "INTEGER"
            },
            {
              "name": "mf03",
              "type": "INTEGER"
            },
            {
              "name": "pc13",
              "type": "INTEGER"
            },
            {
              "name": "pc14",
              "type": "INTEGER"
            },
            {
              "name": "pc15",
              "type": "INTEGER"
            },
            {
              "name": "pc25",
              "type": "INTEGER"
            },
            {
              "name": "pc26",
              "type": "INTEGER"
            },
            {
              "name": "pc27",
              "type": "INTEGER"
            },
            {
              "name": "res",
              "type": "INTEGER"
            }
          ]
        }

zeppelin:
  enabled: true
  runMode: local
  interpreters:
    - file
    - md
    - python
    - sh
  metrics:
    enabled: true
    podMonitor:
      enabled: true

### Data Ingestion (isolated Kafka cluster) ###

kafka:
  podAntiAffinitypreset: hard
  logRetentionHours: 6
  numPartitions: 2
  deleteTopicEnable: true
  resources:
    requests:
      memory: "2Gi"
      cpu: "0.5"
    limits:
      memory: "2Gi"
      cpu: "0.5"
  metrics:
    kafka:
      enabled: true
    jmx:
      enabled: true
    serviceMonitor:
      enabled: true
  zookeeper:
    metrics:
      enabled: true
      serviceMonitor:
        enabled: true

### Benchmark Observability Stack ###

kafdrop:
  enabled: true

tobs:
  enabled: true
  kube-prometheus-stack:
    alertmanager:
      enabled: false # not needed
    prometheus:
      prometheusSpec:
        podMonitorSelectorNilUsesHelmValues: false
        serviceMonitorSelectorNilUsesHelmValues: false
